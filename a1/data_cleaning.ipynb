{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things done before splitting train dataset:\n",
    "- large extreme energy values are dropped (2 of those, handpicked)\n",
    "- observations where area/bedroom ratio doesn't make sense are dropped\n",
    "- some columns are dropped: sticker, price_drop_date, lat, lon, is_promoted\n",
    "- delete occurences where subtype, energy_value or energy_label are missing (we will need subtype for other energy values later on)\n",
    "\n",
    "then we split into train validation test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# -------- removing invalid outliers --------\n",
    "# deleteting the 2 large impossible values from the training set for energy_value\n",
    "train_df = train_df.drop(train_df.nlargest(2, 'energy_value').index)\n",
    "\n",
    "# deleting impossible area/bedroom ratios\n",
    "# minimum area per bedroom\n",
    "min_area_per_bedroom = 6\n",
    "\n",
    "# area per bedroom ratio\n",
    "train_df[\"area_per_bedroom\"] = train_df[\"area\"] / train_df[\"bedrooms\"]\n",
    "\n",
    "# bedroom size is not logical\n",
    "invalid_outliers = train_df[train_df[\"area_per_bedroom\"] < min_area_per_bedroom]\n",
    "train_df = train_df.drop(invalid_outliers.index)\n",
    "\n",
    "# drop the temporary column\n",
    "train_df = train_df.drop(columns=[\"area_per_bedroom\"])\n",
    "\n",
    "# delete occurences where subtype, energy_value or energy_label are missing (we will need subtype for other energy values later on)\n",
    "train_df = train_df.drop(train_df[train_df['subtype'].isna() & (train_df['energy_label'].isna() | train_df['energy_value'].isna())].index)\n",
    "\n",
    "# remove rows where advertiser is \"Your Home\" (only applies to train)\n",
    "train_df = train_df[train_df[\"advertiser\"] != \"Your Home\"]\n",
    "\n",
    "\n",
    "# -------- removing not needed columns --------\n",
    "columns_to_drop = [\"sticker\", \"price_drop_date\", \"lat\", \"lon\", \"is_promoted\"]\n",
    "train_df = train_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "test_df = test_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset\n",
    "target_col = \"price\"\n",
    "\n",
    "train_set, val_set, y_train, y_val = train_test_split(\n",
    "    train_df.drop(columns=[target_col]),  # features only\n",
    "    train_df[target_col],                 # target\n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- specific advertiser removed (accounts for  alot of missing values)\n",
    "- for all energy_values above 10000, replace with median of the energy_label\n",
    "- if energy value is below 0 but label is missing, assign a++ label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- handling outliers --------\n",
    "# compute median energy_value per energy_label (only from train)\n",
    "energy_label_mapping = train_set.groupby('energy_label')['energy_value'].median().to_dict()\n",
    "\n",
    "# replace outliers with the median of their energy_label (only in train)\n",
    "def replace_outlier(row):\n",
    "    if row[\"energy_value\"] > 10000:\n",
    "        return energy_label_mapping.get(row[\"energy_label\"], row[\"energy_value\"])  # use median if available\n",
    "    return row[\"energy_value\"]\n",
    "\n",
    "train_set[\"energy_value\"] = train_set.apply(replace_outlier, axis=1)\n",
    "\n",
    "# do not modify val_set or test_df outliers\n",
    "# keep extreme values in validation to properly test generalization\n",
    "\n",
    "# -------- energy_value below 0 --------\n",
    "# only in train\n",
    "train_set.loc[(train_set['energy_value'] < 0) & (train_set['energy_label'].isna()), 'energy_label'] = 'a++'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most stats used for mapping are defined here: \n",
    "- energy stats: min max median of energy_value per label\n",
    "- median_area_by_bedrooms: median of area per bedrooms\n",
    "- median_by_subtype: median of energy_values based on subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- most stats --------\n",
    "# define energy label hierarchy (higher efficiency first)\n",
    "label_hierarchy = [\"a++\", \"a+\", \"a-\", \"a\", \"b+\", \"b-\", \"b\", \"c+\", \"c-\", \"c\", \"d+\", \"d-\", \"d\", \"e+\", \"e-\", \"e\", \"f\", \"g\"]\n",
    "\n",
    "# compute min, max, and median energy_value per label (only from train)\n",
    "energy_stats = train_set.groupby(\"energy_label\")['energy_value'].agg(['min', 'max', 'median']).dropna()\n",
    "energy_stats = energy_stats.reindex(label_hierarchy)  # apply hierarchy sorting\n",
    "\n",
    "\n",
    "# function to find the best label based on closest median energy_value\n",
    "def impute_label(energy_value):\n",
    "    if np.isnan(energy_value):\n",
    "        return np.nan  # skip missing energy_value\n",
    "    \n",
    "    # find labels where the energy_value falls within the range\n",
    "    valid_labels = energy_stats[(energy_stats['min'] <= energy_value) & (energy_value <= energy_stats['max'])]\n",
    "    \n",
    "    if valid_labels.empty:\n",
    "        return np.nan  # no matching label range found\n",
    "    \n",
    "    # select the label with the closest median energy_value\n",
    "    closest_labels = valid_labels.iloc[(valid_labels['median'] - energy_value).abs().argsort()]\n",
    "    \n",
    "    # prioritize the highest efficiency label if multiple labels have the same median\n",
    "    best_label = closest_labels.index[0]\n",
    "    return best_label\n",
    "\n",
    "# compute median area per bedroom count (only from train)\n",
    "median_area_by_bedrooms = train_set.groupby(\"bedrooms\")[\"area\"].median()\n",
    "\n",
    "# compute median energy_value for each subtype from train_set\n",
    "median_by_subtype = train_set.groupby('subtype')['energy_value'].median()\n",
    "\n",
    "# Define the mapping for grouping energy labels\n",
    "label_grouping = {\n",
    "    \"a++\": \"a\", \"a+\": \"a\", \"a-\": \"a\",\n",
    "    \"b+\": \"b\", \"b-\": \"b\", \"b\": \"b\",\n",
    "    \"c+\": \"c\", \"c-\": \"c\", \"c\": \"c\",\n",
    "    \"d+\": \"d\", \"d-\": \"d\", \"d\": \"d\",\n",
    "    \"e+\": \"e\", \"e-\": \"e\", \"e\": \"e\",\n",
    "    \"f\": \"f\", \"g\": \"g\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code does:\n",
    "- if area is missing, fill it with median of the number of bedrooms for the number of bedrooms the listing has\n",
    "- if energy value is missing and energy label isnt, use the median of the energy label to fill the energy value\n",
    "- if energy label is missing and energy value isnt, impute the closest label to the value\n",
    "- if new building is 1 and it still hasn't been filled so far, assign class a (newer buildings more efficient by law)\n",
    "- if new building is 0 and it still hasnt been filled, map the value based on subtype and then impute closest label to the value\n",
    "- groups the granular categories into the 7 main categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df in [train_set, val_set, test_df]:\n",
    "    # fill missing area values\n",
    "    df[\"area\"] = df[\"area\"].fillna(df[\"bedrooms\"].map(median_area_by_bedrooms))\n",
    "\n",
    "\n",
    "    # fill missing energy_value using the median of its corresponding energy_label if it exists\n",
    "    df.loc[df['energy_value'].isnull() & df['energy_label'].notnull(), 'energy_value'] = df['energy_label'].map(energy_label_mapping)\n",
    "\n",
    "    #!! yes/no?\n",
    "    df['subtype'] = df['subtype'].fillna('Unknown')\n",
    "    df['advertiser'] = df['advertiser'].fillna('Unknown')\n",
    "\n",
    "    # fill missing energy_label based on energy_value\n",
    "    df.loc[df['energy_label'].isna(), 'energy_label'] = df['energy_value'].apply(impute_label)\n",
    "\n",
    "    # assign energy_label = 'a' and fill energy_value for new_building == 1\n",
    "    df.loc[(df['new_building'] == 1) & df['energy_label'].isna(), 'energy_label'] = 'a'\n",
    "    df.loc[(df['new_building'] == 1) & df['energy_value'].isna(), 'energy_value'] = energy_label_mapping['a']\n",
    "\n",
    "    # impute missing values in each dataset where new_building = 0\n",
    "    mask = (df['new_building'] == 0) & (df['energy_value'].isna())\n",
    "    df.loc[mask, 'energy_value'] = df.loc[mask, 'subtype'].map(median_by_subtype)\n",
    "    df.loc[(df['new_building'] == 0) & df['energy_label'].isna(), 'energy_label'] = df['energy_value'].apply(impute_label)\n",
    "\n",
    "    # Group the energy labels according to the label_grouping dictionary\n",
    "    df['energy_label'] = df['energy_label'].map(label_grouping).fillna(df['energy_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned datasets\n",
    "train_set.to_csv(\"./data/cleaned_train.csv\", index=False)\n",
    "val_set.to_csv(\"./data/cleaned_val.csv\", index=False)\n",
    "test_df.to_csv(\"./data/cleaned_test.csv\", index=False)\n",
    "y_train.to_csv(\"./data/y_train.csv\", index=False)\n",
    "y_val.to_csv(\"./data/y_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remaining issues:\n",
    "- woonboot subtype median is nan (`median_by_subtype['Woonboot']`)\n",
    "- when bedroom number is 14, the median area is also nan (`median_area_by_bedrooms[14]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_appartment</th>\n",
       "      <th>area</th>\n",
       "      <th>added_time</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>new_building</th>\n",
       "      <th>postcode</th>\n",
       "      <th>advertiser</th>\n",
       "      <th>foto_amount</th>\n",
       "      <th>subtype</th>\n",
       "      <th>energy_value</th>\n",
       "      <th>energy_label</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18071</th>\n",
       "      <td>tr18071</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107248513</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6180</td>\n",
       "      <td>Immo STILLAVATI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Woning</td>\n",
       "      <td>743.0</td>\n",
       "      <td>g</td>\n",
       "      <td>Henegouwen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_appartment  area  added_time  bedrooms  new_building  \\\n",
       "18071  tr18071          False   NaN   107248513      14.0             0   \n",
       "\n",
       "       postcode        advertiser  foto_amount subtype  energy_value  \\\n",
       "18071      6180  Immo STILLAVATI           2.0  Woning         743.0   \n",
       "\n",
       "      energy_label    province  \n",
       "18071            g  Henegouwen  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code from above, just condensed in 1 cell for easy executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load datasets\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# -------- removing invalid outliers --------\n",
    "# deleteting the 2 large impossible values from the training set for energy_value\n",
    "train_df = train_df.drop(train_df.nlargest(2, 'energy_value').index)\n",
    "\n",
    "# deleting impossible area/bedroom ratios\n",
    "# minimum area per bedroom\n",
    "min_area_per_bedroom = 6\n",
    "\n",
    "# area per bedroom ratio\n",
    "train_df[\"area_per_bedroom\"] = train_df[\"area\"] / train_df[\"bedrooms\"]\n",
    "\n",
    "# bedroom size is not logical\n",
    "invalid_outliers = train_df[train_df[\"area_per_bedroom\"] < min_area_per_bedroom]\n",
    "train_df = train_df.drop(invalid_outliers.index)\n",
    "\n",
    "# drop the temporary column\n",
    "train_df = train_df.drop(columns=[\"area_per_bedroom\"])\n",
    "\n",
    "# delete occurences where subtype, energy_value or energy_label are missing (we will need subtype for other energy values later on)\n",
    "train_df = train_df.drop(train_df[train_df['subtype'].isna() & (train_df['energy_label'].isna() | train_df['energy_value'].isna())].index)\n",
    "\n",
    "# remove rows where advertiser is \"Your Home\" (only applies to train)\n",
    "train_df = train_df[train_df[\"advertiser\"] != \"Your Home\"]\n",
    "\n",
    "\n",
    "# -------- removing not needed columns --------\n",
    "columns_to_drop = [\"sticker\", \"price_drop_date\", \"lat\", \"lon\", \"is_promoted\"]\n",
    "train_df = train_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "test_df = test_df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "# split train dataset\n",
    "target_col = \"price\"\n",
    "\n",
    "train_set, val_set, y_train, y_val = train_test_split(\n",
    "    train_df.drop(columns=[target_col]),  # features only\n",
    "    train_df[target_col],                 # target\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# -------- handling outliers --------\n",
    "# compute median energy_value per energy_label (only from train)\n",
    "energy_label_mapping = train_set.groupby('energy_label')['energy_value'].median().to_dict()\n",
    "\n",
    "# replace outliers with the median of their energy_label (only in train)\n",
    "def replace_outlier(row):\n",
    "    if row[\"energy_value\"] > 10000:\n",
    "        return energy_label_mapping.get(row[\"energy_label\"], row[\"energy_value\"])  # use median if available\n",
    "    return row[\"energy_value\"]\n",
    "\n",
    "train_set[\"energy_value\"] = train_set.apply(replace_outlier, axis=1)\n",
    "\n",
    "# do not modify val_set or test_df outliers\n",
    "# keep extreme values in validation to properly test generalization\n",
    "\n",
    "# -------- energy_value below 0 --------\n",
    "# only in train\n",
    "train_set.loc[(train_set['energy_value'] < 0) & (train_set['energy_label'].isna()), 'energy_label'] = 'a++'\n",
    "\n",
    "# -------- most stats --------\n",
    "# define energy label hierarchy (higher efficiency first)\n",
    "label_hierarchy = [\"a++\", \"a+\", \"a-\", \"a\", \"b+\", \"b-\", \"b\", \"c+\", \"c-\", \"c\", \"d+\", \"d-\", \"d\", \"e+\", \"e-\", \"e\", \"f\", \"g\"]\n",
    "\n",
    "# compute min, max, and median energy_value per label (only from train)\n",
    "energy_stats = train_set.groupby(\"energy_label\")['energy_value'].agg(['min', 'max', 'median']).dropna()\n",
    "energy_stats = energy_stats.reindex(label_hierarchy)  # apply hierarchy sorting\n",
    "\n",
    "\n",
    "# function to find the best label based on closest median energy_value\n",
    "def impute_label(energy_value):\n",
    "    if np.isnan(energy_value):\n",
    "        return np.nan  # skip missing energy_value\n",
    "    \n",
    "    # find labels where the energy_value falls within the range\n",
    "    valid_labels = energy_stats[(energy_stats['min'] <= energy_value) & (energy_value <= energy_stats['max'])]\n",
    "    \n",
    "    if valid_labels.empty:\n",
    "        return np.nan  # no matching label range found\n",
    "    \n",
    "    # select the label with the closest median energy_value\n",
    "    closest_labels = valid_labels.iloc[(valid_labels['median'] - energy_value).abs().argsort()]\n",
    "    \n",
    "    # prioritize the highest efficiency label if multiple labels have the same median\n",
    "    best_label = closest_labels.index[0]\n",
    "    return best_label\n",
    "\n",
    "# compute median area per bedroom count (only from train)\n",
    "median_area_by_bedrooms = train_set.groupby(\"bedrooms\")[\"area\"].median()\n",
    "\n",
    "# compute median energy_value for each subtype from train_set\n",
    "median_by_subtype = train_set.groupby('subtype')['energy_value'].median()\n",
    "\n",
    "# Define the mapping for grouping energy labels\n",
    "label_grouping = {\n",
    "    \"a++\": \"a\", \"a+\": \"a\", \"a-\": \"a\",\n",
    "    \"b+\": \"b\", \"b-\": \"b\", \"b\": \"b\",\n",
    "    \"c+\": \"c\", \"c-\": \"c\", \"c\": \"c\",\n",
    "    \"d+\": \"d\", \"d-\": \"d\", \"d\": \"d\",\n",
    "    \"e+\": \"e\", \"e-\": \"e\", \"e\": \"e\",\n",
    "    \"f\": \"f\", \"g\": \"g\"}\n",
    "\n",
    "for df in [train_set, val_set, test_df]:\n",
    "    # fill missing area values\n",
    "    df[\"area\"] = df[\"area\"].fillna(df[\"bedrooms\"].map(median_area_by_bedrooms))\n",
    "\n",
    "\n",
    "    # fill missing energy_value using the median of its corresponding energy_label if it exists\n",
    "    df.loc[df['energy_value'].isnull() & df['energy_label'].notnull(), 'energy_value'] = df['energy_label'].map(energy_label_mapping)\n",
    "\n",
    "    #!! yes/no?\n",
    "    df['subtype'] = df['subtype'].fillna('Unknown')\n",
    "    df['advertiser'] = df['advertiser'].fillna('Unknown')\n",
    "\n",
    "    # fill missing energy_label based on energy_value\n",
    "    df.loc[df['energy_label'].isna(), 'energy_label'] = df['energy_value'].apply(impute_label)\n",
    "\n",
    "    # assign energy_label = 'a' and fill energy_value for new_building == 1\n",
    "    df.loc[(df['new_building'] == 1) & df['energy_label'].isna(), 'energy_label'] = 'a'\n",
    "    df.loc[(df['new_building'] == 1) & df['energy_value'].isna(), 'energy_value'] = energy_label_mapping['a']\n",
    "\n",
    "    # impute missing values in each dataset where new_building = 0\n",
    "    mask = (df['new_building'] == 0) & (df['energy_value'].isna())\n",
    "    df.loc[mask, 'energy_value'] = df.loc[mask, 'subtype'].map(median_by_subtype)\n",
    "    df.loc[(df['new_building'] == 0) & df['energy_label'].isna(), 'energy_label'] = df['energy_value'].apply(impute_label)\n",
    "\n",
    "    # Group the energy labels according to the label_grouping dictionary\n",
    "    df['energy_label'] = df['energy_label'].map(label_grouping).fillna(df['energy_label'])\n",
    "\n",
    "# save cleaned datasets\n",
    "train_set.to_csv(\"./data/cleaned_train.csv\", index=False)\n",
    "val_set.to_csv(\"./data/cleaned_val.csv\", index=False)\n",
    "test_df.to_csv(\"./data/cleaned_test.csv\", index=False)\n",
    "y_train.to_csv(\"./data/y_train.csv\", index=False)\n",
    "y_val.to_csv(\"./data/y_val.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
